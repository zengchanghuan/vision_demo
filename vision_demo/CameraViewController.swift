import UIKit
import AVFoundation
import Vision

final class CameraViewController: UIViewController {

    // MARK: - UI

    private let gestureLabel: UILabel = {
        let label = UILabel()
        label.text = "å‡†å¤‡ä¸­..."
        label.textColor = .white
        label.font = .systemFont(ofSize: 22, weight: .bold)
        label.textAlignment = .center
        label.backgroundColor = UIColor.black.withAlphaComponent(0.5)
        label.layer.cornerRadius = 8
        label.layer.masksToBounds = true
        return label
    }()

    /// è°ƒè¯•ä¿¡æ¯æ˜¾ç¤ºLabelï¼ˆå¤šè¡Œï¼‰
    private let debugLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .monospacedSystemFont(ofSize: 12, weight: .regular)
        label.textColor = .white
        label.backgroundColor = UIColor.black.withAlphaComponent(0.4)
        label.layer.cornerRadius = 8
        label.translatesAutoresizingMaskIntoConstraints = false
        label.text = "ç­‰å¾…è¯†åˆ«..."
        return label
    }()
    
    /// æ¨¡å¼åˆ‡æ¢æ§ä»¶
    private let modeSegmentedControl: UISegmentedControl = {
        let control = UISegmentedControl(items: ["æ‰‹åŠ¿è¯†åˆ«", "äººè„¸è·Ÿéš", "ç›®æ ‡è·Ÿè¸ª"])
        control.selectedSegmentIndex = 0
        control.backgroundColor = UIColor.white.withAlphaComponent(0.3)
        control.selectedSegmentTintColor = .systemYellow
        return control
    }()

    /// Debugå¼€å…³çŠ¶æ€
    private var isDebugEnabled = true

    // MARK: - Camera & Vision

    private let captureSession = AVCaptureSession()
    private var previewLayer: AVCaptureVideoPreviewLayer!
    private let videoQueue = DispatchQueue(label: "camera.video.queue")

    private lazy var handPoseRequest: VNDetectHumanHandPoseRequest = {
        let request = VNDetectHumanHandPoseRequest(completionHandler: self.handleHandPose)
        request.maximumHandCount = 1
        return request
    }()

    /// æ£€æµ‹æ¨¡å¼æšä¸¾
    enum DetectionMode: Int {
        case handGesture = 0
        case faceTracking = 1
        case objectTracking = 2
    }

    private var currentMode: DetectionMode = .handGesture {
        didSet {
            // å…ˆé‡ç½®æ‰€æœ‰è¿½è¸ªå™¨ï¼Œé˜²æ­¢æ—§æ¨¡å¼çš„å›è°ƒå¹²æ‰°
            resetTrackers()
            // å†æ›´æ–°UIå¹¶å¯åŠ¨æ–°æ¨¡å¼æ‰€éœ€çš„è¿½è¸ªå™¨
            updateUIForMode()
        }
    }

    // MARK: - Detectors
    
    private var classifier = HandGestureClassifier()
    private let faceDetector = FaceDetector()
    private let objectTracker = ObjectTracker()
    
    // MARK: - Tracking UI
    
    private let trackingView = TrackingView(frame: .zero)
    
    // MARK: - è°ƒå‚æ¨¡å¼
    
    /// è°ƒå‚æ¨¡å¼å¼€å…³
    private let isTuningModeEnabled = false // é»˜è®¤å…³é—­ï¼Œè®©å‡ºç©ºé—´ç»™æ¨¡å¼åˆ‡æ¢

    /// ç»Ÿè®¡ç®¡ç†å™¨
    private let statsManager = HandGestureStatsManager()

    /// æ˜¯å¦æ­£åœ¨é‡‡é›†æ ·æœ¬
    private var isCollectingSamples = false

    /// å½“å‰çœŸå®æ‰‹åŠ¿ï¼ˆç”¨æˆ·åœ¨UIä¸Šé€‰æ‹©çš„ï¼‰
    private var currentGroundTruthGesture: HandGestureType = .unknown

    /// ç»Ÿè®¡æ›´æ–°è®¡æ•°å™¨ï¼ˆç”¨äºæ§åˆ¶UIæ›´æ–°é¢‘ç‡ï¼‰
    private var statsUpdateCounter = 0

    // MARK: - è°ƒå‚UIç»„ä»¶

    /// çœŸå®æ‰‹åŠ¿é€‰æ‹©æ§ä»¶
    private let groundTruthSegmentedControl: UISegmentedControl = {
        let control = UISegmentedControl(items: ["æœªçŸ¥", "V", "OK", "æ‰‹æŒ", "æ‹³å¤´", "é£ŸæŒ‡"])
        control.selectedSegmentIndex = 0
        control.backgroundColor = UIColor.white.withAlphaComponent(0.3)
        control.selectedSegmentTintColor = .systemBlue
        return control
    }()

    /// å¼€å§‹/åœæ­¢é‡‡é›†æŒ‰é’®
    private let collectButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("å¼€å§‹é‡‡é›†", for: .normal)
        button.backgroundColor = .systemGreen
        button.setTitleColor(.white, for: .normal)
        button.layer.cornerRadius = 8
        button.titleLabel?.font = .systemFont(ofSize: 16, weight: .semibold)
        return button
    }()

    /// é‡ç½®ç»Ÿè®¡æŒ‰é’®
    private let resetButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("é‡ç½®ç»Ÿè®¡", for: .normal)
        button.backgroundColor = .systemOrange
        button.setTitleColor(.white, for: .normal)
        button.layer.cornerRadius = 8
        button.titleLabel?.font = .systemFont(ofSize: 16, weight: .semibold)
        return button
    }()

    /// å¯¼å‡ºç»Ÿè®¡æŒ‰é’®
    private let exportButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("å¯¼å‡ºç»Ÿè®¡", for: .normal)
        button.backgroundColor = .systemBlue
        button.setTitleColor(.white, for: .normal)
        button.layer.cornerRadius = 8
        button.titleLabel?.font = .systemFont(ofSize: 16, weight: .semibold)
        return button
    }()

    /// ç»Ÿè®¡å±•ç¤ºæ–‡æœ¬åŒºåŸŸ
    private let statsTextView: UITextView = {
        let textView = UITextView()
        textView.isEditable = false
        textView.isScrollEnabled = true
        textView.backgroundColor = UIColor.black.withAlphaComponent(0.6)
        textView.textColor = .white
        textView.font = .systemFont(ofSize: 12)
        textView.layer.cornerRadius = 8
        textView.text = "ç­‰å¾…é‡‡é›†æ•°æ®..."
        return textView
    }()

    /// åº•éƒ¨è°ƒå‚é¢æ¿å®¹å™¨
    private let tuningPanelStackView: UIStackView = {
        let stackView = UIStackView()
        stackView.axis = .vertical
        stackView.spacing = 12
        stackView.alignment = .fill
        stackView.distribution = .fill
        stackView.backgroundColor = UIColor.black.withAlphaComponent(0.4)
        stackView.layer.cornerRadius = 12
        stackView.isLayoutMarginsRelativeArrangement = true
        stackView.layoutMargins = UIEdgeInsets(top: 12, left: 12, bottom: 12, right: 12)
        return stackView
    }()

    // MARK: - æ—¶é—´å¹³æ»‘ï¼ˆå¤šå¸§æŠ•ç¥¨ï¼‰

    /// æœ€è¿‘ N å¸§çš„æ‰‹åŠ¿è¯†åˆ«ç»“æœå†å²
    private var gestureHistory: [HandGestureType] = []

    /// å†å²çª—å£å¤§å°ï¼ˆå¸§æ•°ï¼‰
    private let gestureHistoryLimit = 5

    /// å½“å‰ç¨³å®šçš„æ‰‹åŠ¿ç±»å‹ï¼ˆç»è¿‡æ—¶é—´å¹³æ»‘åçš„ç»“æœï¼‰
    private var stableGestureType: HandGestureType? {
        didSet {
            updateGestureLabel()
        }
    }

    // MARK: - Lifecycle

    override func viewDidLoad() {
        super.viewDidLoad()
        view.backgroundColor = .black
        setupPreviewLayer()
        setupGestureLabel()
        setupModeControl()
        setupTrackingView()
        setupDebugUI()
        setupDebugLogging()
        setupDetectors()
        
        if isTuningModeEnabled {
            setupTuningPanel()
        }
        checkCameraAuthorizationAndStart()
    }
    
    override func viewDidLayoutSubviews() {
        super.viewDidLayoutSubviews()
        previewLayer?.frame = view.bounds
        trackingView.frame = view.bounds
        
        let topSafe = view.safeAreaInsets.top
        
        // æ¨¡å¼åˆ‡æ¢æ§ä»¶
        modeSegmentedControl.frame = CGRect(
            x: 16,
            y: topSafe + 10,
            width: view.bounds.width - 32,
            height: 32
        )
        
        gestureLabel.frame = CGRect(
            x: 16,
            y: modeSegmentedControl.frame.maxY + 16,
            width: view.bounds.width - 32,
            height: 44
        )
        
        // å¸ƒå±€debugLabelï¼ˆåœ¨gestureLabelä¸‹æ–¹ï¼‰
        if isDebugEnabled {
            debugLabel.frame = CGRect(
                x: 16,
                y: gestureLabel.frame.maxY + 8,
                width: view.bounds.width - 32,
                height: min(120, view.bounds.height - gestureLabel.frame.maxY - 200)
            )
        }
        
        if isTuningModeEnabled {
            layoutTuningPanel()
        }
    }
    
    private func setupModeControl() {
        view.addSubview(modeSegmentedControl)
        modeSegmentedControl.addTarget(self, action: #selector(modeChanged(_:)), for: .valueChanged)
    }
    
    private func setupTrackingView() {
        view.addSubview(trackingView)
    }
    
    private func setupDetectors() {
        // é…ç½®äººè„¸æ£€æµ‹å›è°ƒ
        faceDetector.onFaceDetected = { [weak self] normalizedRect in
            guard let self = self else { return }
            // print("Face detected at: \(normalizedRect)")
            DispatchQueue.main.async {
                // ä½¿ç”¨ previewLayer å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºè§†å›¾åæ ‡
                // è¿™èƒ½è‡ªåŠ¨å¤„ç† videoGravity (å¦‚ .resizeAspectFill) å¸¦æ¥çš„è£å‰ªå’Œç¼©æ”¾åç§»
                let convertedRect = self.previewLayer.layerRectConverted(fromMetadataOutputRect: normalizedRect)
                
                // äººè„¸è·Ÿéšä½¿ç”¨é»„è‰²è™šçº¿æ¡†
                self.trackingView.updateTrackingRect(convertedRect, color: .yellow, isDashed: true, isNormalized: false)
                self.gestureLabel.text = "æ£€æµ‹åˆ°äººè„¸"
            }
        }
        
        faceDetector.onNoFaceDetected = { [weak self] in
            // print("No face detected")
            DispatchQueue.main.async {
                // æœªæ£€æµ‹åˆ°äººè„¸æ—¶ï¼Œæ˜¾ç¤ºçº¢è‰²ä¸­å¿ƒæ¡†ï¼ˆæœç´¢çŠ¶æ€ï¼‰
                let centerRect = CGRect(x: 0.25, y: 0.35, width: 0.5, height: 0.3)
                self?.trackingView.updateTrackingRect(centerRect, color: .red, isDashed: false)
                self?.gestureLabel.text = "æœªæ£€æµ‹åˆ°äººè„¸"
            }
        }
        
        // é…ç½®ç›®æ ‡è·Ÿè¸ªå›è°ƒ
        objectTracker.onTrackingUpdate = { [weak self] rect in
            guard let self = self else { return }
            DispatchQueue.main.async {
                // rectï¼š0~1 çš„å½’ä¸€åŒ–å…ƒæ•°æ®åæ ‡ï¼ˆåŸç‚¹å·¦ä¸Šï¼‰
                // ä½¿ç”¨ previewLayer è½¬æˆè§†å›¾åæ ‡ï¼Œè‡ªåŠ¨å¤„ç†è£å‰ª/æ¯”ä¾‹
                let convertedRect = self.previewLayer.layerRectConverted(fromMetadataOutputRect: rect)
                self.trackingView.updateTrackingRect(convertedRect,
                                                     color: .green,
                                                     isDashed: false,
                                                     isNormalized: false)
                self.gestureLabel.text = "æ­£åœ¨è·Ÿè¸ªç›®æ ‡"
            }
        }
        
        objectTracker.onTrackingLost = { [weak self] in
            DispatchQueue.main.async {
                self?.trackingView.clear()
                self?.gestureLabel.text = "ç›®æ ‡ä¸¢å¤±æˆ–æœªé€‰æ‹© (ç‚¹å‡»å±å¹•é€‰æ‹©)"
            }
        }
    }
    
    @objc private func modeChanged(_ sender: UISegmentedControl) {
        guard let mode = DetectionMode(rawValue: sender.selectedSegmentIndex) else { return }
        print("Mode Changed to: \(mode)")
        currentMode = mode
    }
    
    private func updateUIForMode() {
        print("Updating UI for mode: \(currentMode)")
        trackingView.clear()
        
        switch currentMode {
        case .handGesture:
            gestureLabel.text = "è¯·æŠŠæ‰‹ä¼¸åˆ°é•œå¤´å‰"
            gestureLabel.isHidden = false
            debugLabel.isHidden = !isDebugEnabled
            if isTuningModeEnabled { tuningPanelStackView.isHidden = false }
            
        case .faceTracking:
            gestureLabel.text = "æ­£åœ¨åˆå§‹åŒ–äººè„¸æ£€æµ‹..."
            gestureLabel.isHidden = false
            debugLabel.isHidden = true
            if isTuningModeEnabled { tuningPanelStackView.isHidden = true }
            print("Starting face detector...")
            faceDetector.start()
            
        case .objectTracking:
            gestureLabel.text = "è¯·ç‚¹å‡»å±å¹•é€‰æ‹©è·Ÿè¸ªç›®æ ‡"
            gestureLabel.isHidden = false
            debugLabel.isHidden = true
            if isTuningModeEnabled { tuningPanelStackView.isHidden = true }
        }
    }
    
    private func resetTrackers() {
        faceDetector.stop()
        objectTracker.stop()
    }
    
    // MARK: - Touch Handling
    
    override func touchesBegan(_ touches: Set<UITouch>, with event: UIEvent?) {
        guard currentMode == .objectTracking, let touch = touches.first else { return }

        let location = touch.location(in: view)

        // åœ¨è§†å›¾åæ ‡ç³»ä¸­ï¼Œä»¥ç‚¹å‡»ç‚¹ä¸ºä¸­å¿ƒåˆ›å»ºä¸€ä¸ª 100x100 çš„æ­£æ–¹å½¢æ¡†
        let boxSize: CGFloat = 100
        let boxRectInView = CGRect(
            x: location.x - boxSize / 2,
            y: location.y - boxSize / 2,
            width: boxSize,
            height: boxSize
        )

        // é€šè¿‡ previewLayer è½¬æˆ 0~1 çš„å…ƒæ•°æ®åæ ‡ï¼Œä¾› Vision è·Ÿè¸ªä½¿ç”¨
        let metadataRect = previewLayer.metadataOutputRectConverted(fromLayerRect: boxRectInView)

        // ç”¨å…ƒæ•°æ®åæ ‡å¯åŠ¨ç›®æ ‡è·Ÿè¸ª
        objectTracker.initializeTracking(with: metadataRect)

        // åœ¨å±å¹•ä¸Šç«‹å³ç”»å‡ºç”¨æˆ·é€‰ä¸­çš„æ­£æ–¹å½¢æ¡†ï¼ˆè¿™é‡Œä½¿ç”¨çš„æ˜¯è§†å›¾åæ ‡ï¼Œæ‰€ä»¥ isNormalized = falseï¼‰
        trackingView.updateTrackingRect(boxRectInView,
                                        color: .green,
                                        isDashed: false,
                                        isNormalized: false)
        gestureLabel.text = "ç›®æ ‡å·²é€‰æ‹©ï¼Œå¼€å§‹è·Ÿè¸ª"
    }

    // MARK: - Setup UI

    private func setupPreviewLayer() {
        previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
        previewLayer.videoGravity = .resizeAspectFill
        view.layer.insertSublayer(previewLayer, at: 0)
    }

    private func setupGestureLabel() {
        view.addSubview(gestureLabel)
    }

    /// è®¾ç½®è°ƒè¯•UI
    private func setupDebugUI() {
        view.addSubview(debugLabel)
        debugLabel.isHidden = !isDebugEnabled

        // æ·»åŠ Debugå¼€å…³æŒ‰é’®ï¼ˆå³ä¸Šè§’ï¼‰
        navigationItem.rightBarButtonItem = UIBarButtonItem(
            title: "Debug",
            style: .plain,
            target: self,
            action: #selector(toggleDebug)
        )
    }

    /// è®¾ç½®è°ƒå‚é¢æ¿UI
    private func setupTuningPanel() {
        view.addSubview(tuningPanelStackView)

        // æ·»åŠ æ‰‹åŠ¿é€‰æ‹©æ§ä»¶
        tuningPanelStackView.addArrangedSubview(groundTruthSegmentedControl)
        groundTruthSegmentedControl.addTarget(self, action: #selector(groundTruthChanged(_:)), for: .valueChanged)

        // æ·»åŠ æŒ‰é’®å®¹å™¨
        let buttonStackView = UIStackView()
        buttonStackView.axis = .horizontal
        buttonStackView.spacing = 8
        buttonStackView.distribution = .fillEqually

        buttonStackView.addArrangedSubview(collectButton)
        buttonStackView.addArrangedSubview(resetButton)
        buttonStackView.addArrangedSubview(exportButton)

        collectButton.addTarget(self, action: #selector(collectButtonTapped), for: .touchUpInside)
        resetButton.addTarget(self, action: #selector(resetButtonTapped), for: .touchUpInside)
        exportButton.addTarget(self, action: #selector(exportButtonTapped), for: .touchUpInside)

        tuningPanelStackView.addArrangedSubview(buttonStackView)

        // æ·»åŠ ç»Ÿè®¡æ–‡æœ¬åŒºåŸŸ
        tuningPanelStackView.addArrangedSubview(statsTextView)
        statsTextView.heightAnchor.constraint(equalToConstant: 150).isActive = true
    }

    /// å¸ƒå±€è°ƒå‚é¢æ¿
    private func layoutTuningPanel() {
        let bottomSafe = view.safeAreaInsets.bottom
        let panelHeight: CGFloat = 280
        tuningPanelStackView.frame = CGRect(
            x: 16,
            y: view.bounds.height - panelHeight - bottomSafe - 16,
            width: view.bounds.width - 32,
            height: panelHeight
        )
    }

    // MARK: - Debug è®¾ç½®

    /// è®¾ç½®è°ƒè¯•æ—¥å¿—è¾“å‡ºï¼ˆä»…åœ¨ DEBUG æ¨¡å¼ä¸‹å¯ç”¨ï¼‰
    private func setupDebugLogging() {
        #if DEBUG
        classifier.debugLogHandler = { message in
            print("[HandGestureDebug]", message)
        }
        #endif

        // è®¾ç½®è°ƒè¯•ä¿¡æ¯å›è°ƒï¼Œç”¨äºUIæ˜¾ç¤º
        classifier.debugInfoHandler = { [weak self] info in
            DispatchQueue.main.async {
                self?.updateDebugUI(with: info)
            }
        }
    }

    /// åˆ‡æ¢Debugæ˜¾ç¤º
    @objc private func toggleDebug() {
        isDebugEnabled.toggle()
        debugLabel.isHidden = !isDebugEnabled

        if isDebugEnabled {
            classifier.debugInfoHandler = { [weak self] info in
                DispatchQueue.main.async {
                    self?.updateDebugUI(with: info)
                }
            }
        } else {
            classifier.debugInfoHandler = nil
        }
    }

    /// æ›´æ–°è°ƒè¯•UIæ˜¾ç¤º
    private func updateDebugUI(with info: HandGestureClassifier.HandGestureDebugInfo) {
        guard isDebugEnabled else { return }

        var lines: [String] = []
        lines.append("Gesture: \(info.gesture.rawValue)")
        lines.append("Scores: V/OK/Palm/Fist/Idx = \(info.scoreV)/\(info.scoreOK)/\(info.scorePalm)/\(info.scoreFist)/\(info.scoreIndexFinger)")
        lines.append("gaps: thumb-idx=\(String(format: "%.3f", info.gapThumbIndex)), idx-mid=\(String(format: "%.3f", info.gapIndexMiddle))")
        lines.append("ratios: idx/mid=\(String(format: "%.2f", info.indexToMiddleRatio)), ring/mid=\(String(format: "%.2f", info.ringToMiddleRatio))")
        lines.append("straightCount = \(info.straightCount)")

        debugLabel.text = lines.joined(separator: "\n")
    }

    // MARK: - Camera

    private func checkCameraAuthorizationAndStart() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            setupCaptureSession()
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { granted in
                DispatchQueue.main.async {
                    if granted {
                        self.setupCaptureSession()
                    } else {
                        self.gestureLabel.text = "ç›¸æœºæƒé™è¢«æ‹’ç»"
                    }
                }
            }
        default:
            gestureLabel.text = "æ— ç›¸æœºæƒé™ï¼Œè¯·åœ¨è®¾ç½®ä¸­å¼€å¯"
        }
    }

    private func setupCaptureSession() {
        captureSession.beginConfiguration()

        // åˆ†è¾¨ç‡ä½ ä¹Ÿå¯ä»¥æ¢æˆ .hd1280x720 ä¿æŒæ€§èƒ½
        if captureSession.canSetSessionPreset(.high) {
            captureSession.sessionPreset = .high
        }

        guard
            let device = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                 for: .video,
                                                 position: .front),
            let input = try? AVCaptureDeviceInput(device: device),
            captureSession.canAddInput(input)
        else {
            gestureLabel.text = "æ— æ³•æ‰“å¼€ç›¸æœº"
            captureSession.commitConfiguration()
            return
        }
        captureSession.addInput(input)

        let output = AVCaptureVideoDataOutput()
        output.alwaysDiscardsLateVideoFrames = true
        output.setSampleBufferDelegate(self, queue: videoQueue)

        if captureSession.canAddOutput(output) {
            captureSession.addOutput(output)
        }

        if let conn = output.connection(with: .video) {
            if conn.isVideoOrientationSupported {
                conn.videoOrientation = .portrait
            }
            // ä¸è¦åœ¨è¿™é‡Œè®¾ç½® isVideoMirroredï¼Œè®© Vision å¤„ç†åŸå§‹æ•°æ®
            // if conn.isVideoMirroringSupported {
            //    conn.isVideoMirrored = true
            // }
        }

        captureSession.commitConfiguration()

        // startRunning åº”è¯¥åœ¨åå°çº¿ç¨‹æ‰§è¡Œï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        videoQueue.async { [weak self] in
            self?.captureSession.startRunning()
        }
    }

    // MARK: - Vision å¤„ç†
    
    private func processSampleBuffer(_ sampleBuffer: CMSampleBuffer) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        
        switch currentMode {
        case .handGesture:
            let handler = VNImageRequestHandler(
                cvPixelBuffer: pixelBuffer,
                orientation: .upMirrored,    // å‰ç½® + é•œåƒ
                options: [:]
            )
            do {
                try handler.perform([handPoseRequest])
            } catch {
                print("Vision perform error: \(error)")
            }
            
        case .faceTracking:
            // ä½¿ç”¨ .leftMirrored æ–¹å‘ï¼Œé€‚é…å‰ç½®æ‘„åƒå¤´ç«–å±çš„å¸¸è§æ–¹å‘
             if Int.random(in: 0...60) == 0 { print("Processing face detection frame...") }
            faceDetector.detectFaces(in: pixelBuffer, orientation: .leftMirrored)
            
        case .objectTracking:
            objectTracker.trackObject(in: pixelBuffer)
        }
    }

    private func handleHandPose(request: VNRequest, error: Error?) {
        if let error = error {
            print("Hand pose request error: \(error)")
            return
        }

        guard let results = request.results as? [VNHumanHandPoseObservation],
              let observation = results.first
        else {
            // è¿ç»­å¤šå¸§æ²¡æœ‰æ£€æµ‹åˆ°æ‰‹ï¼Œæ¸…ç©ºå†å²å¹¶é‡ç½®ç¨³å®šæ‰‹åŠ¿
            clearGestureHistory()
            return
        }

        // ä¼˜å…ˆä½¿ç”¨ classifyWithFeatures è·å–å®Œæ•´ç»“æœï¼ˆåŒ…å«ç‰¹å¾å‘é‡ï¼‰
        guard let result = classifier.classifyWithFeatures(from: observation) else {
            clearGestureHistory()
            return
        }

        // åŸæœ‰UIæ˜¾ç¤ºé€»è¾‘ä½¿ç”¨é¢„æµ‹ç»“æœ
        updateStableGesture(with: result.predicted)

        // å¦‚æœæ»¡è¶³é‡‡é›†æ¡ä»¶ï¼Œè®°å½•æ ·æœ¬
        if isTuningModeEnabled && isCollectingSamples && currentGroundTruthGesture != .unknown {
            statsManager.recordSample(
                groundTruth: currentGroundTruthGesture,
                predicted: result.predicted,
                features: result.features
            )

            // æ¯30å¸§æ›´æ–°ä¸€æ¬¡ç»Ÿè®¡æ–‡æœ¬ï¼ˆé¿å…UIæŠ–åŠ¨ï¼‰
            statsUpdateCounter += 1
            if statsUpdateCounter >= 30 {
                statsUpdateCounter = 0
                DispatchQueue.main.async { [weak self] in
                    self?.refreshStatsText()
                }
            }
        }
    }

    // MARK: - æ‰‹åŠ¿å¹³æ»‘ & UI

    /// æ›´æ–°ç¨³å®šæ‰‹åŠ¿ï¼ˆåŸºäºæ»‘åŠ¨çª—å£çš„ä¼—æ•°ç»Ÿè®¡ï¼‰
    /// - Parameter newGesture: æ–°è¯†åˆ«åˆ°çš„æ‰‹åŠ¿
    private func updateStableGesture(with newGesture: HandGestureType) {
        // å°†æ–°æ‰‹åŠ¿æ·»åŠ åˆ°å†å²çª—å£
        gestureHistory.append(newGesture)

        // ä¿æŒå†å²çª—å£å¤§å°
        if gestureHistory.count > gestureHistoryLimit {
            gestureHistory.removeFirst()
        }

        // ç»Ÿè®¡ä¼—æ•°ï¼ˆå‡ºç°æ¬¡æ•°æœ€å¤šçš„æ‰‹åŠ¿ï¼‰
        let counts = Dictionary(grouping: gestureHistory, by: { $0 })
            .mapValues { $0.count }

        guard let (mostFrequentGesture, count) = counts.max(by: { $0.value < $1.value }) else {
            stableGestureType = .unknown
            return
        }

        // è®¡ç®—è¯¥æ‰‹åŠ¿åœ¨å†å²çª—å£ä¸­çš„å æ¯”
        let ratio = Double(count) / Double(gestureHistory.count)

        // æ ¹æ®æ‰‹åŠ¿ç±»å‹åº”ç”¨ä¸åŒçš„ç¨³å®šæ€§é˜ˆå€¼
        // OK æ‰‹åŠ¿è¦æ±‚æ›´ä¸¥æ ¼ï¼ˆ90%ï¼‰ï¼Œå…¶ä»–æ‰‹åŠ¿ç›¸å¯¹å®½æ¾ï¼ˆ75%ï¼‰
        let threshold: Double
        switch mostFrequentGesture {
        case .okSign:
            threshold = 0.9  // OK æ‰‹åŠ¿éœ€è¦ 90% çš„å¸§ä¸€è‡´æ‰ç®—ç¨³å®š
        case .vSign, .palm:
            threshold = 0.75  // V æ‰‹åŠ¿å’Œå¼ å¼€æ‰‹æŒéœ€è¦ 75% çš„å¸§ä¸€è‡´
        case .fist, .indexFinger:
            threshold = 0.75  // æ‹³å¤´å’Œé£ŸæŒ‡éœ€è¦ 75% çš„å¸§ä¸€è‡´
        default:
            threshold = 0.0  // unknown æˆ–å…¶ä»–æœªå¤„ç†æ‰‹åŠ¿
        }

        // åªæœ‰å½“å æ¯”è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œæ‰è®¤ä¸ºæ‰‹åŠ¿ç¨³å®š
        if ratio >= threshold {
            stableGestureType = mostFrequentGesture
        } else {
            stableGestureType = .unknown
        }
    }

    /// æ¸…ç©ºæ‰‹åŠ¿å†å²ï¼ˆå½“è¿ç»­å¤šå¸§æ£€æµ‹ä¸åˆ°æ‰‹æ—¶è°ƒç”¨ï¼‰
    private func clearGestureHistory() {
        gestureHistory.removeAll()
        stableGestureType = .unknown
    }

    /// æ›´æ–° UI æ˜¾ç¤ºï¼ˆåœ¨ä¸»çº¿ç¨‹æ‰§è¡Œï¼‰
    private func updateGestureLabel() {
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }

            switch self.stableGestureType {
            case .vSign:
                self.gestureLabel.text = "è¯†åˆ«åˆ°ï¼šâœŒï¸ V æ‰‹åŠ¿"
            case .okSign:
                self.gestureLabel.text = "è¯†åˆ«åˆ°ï¼šğŸ‘Œ OK æ‰‹åŠ¿"
            case .palm:
                self.gestureLabel.text = "è¯†åˆ«åˆ°ï¼šğŸ– æ‰‹æŒå¼ å¼€"
            case .fist:
                self.gestureLabel.text = "è¯†åˆ«åˆ°ï¼šâœŠ æ‹³å¤´"
            case .indexFinger:
                self.gestureLabel.text = "è¯†åˆ«åˆ°ï¼šâ˜ï¸ é£ŸæŒ‡"
            default:
                self.gestureLabel.text = "è¯·æŠŠæ‰‹ä¼¸åˆ°é•œå¤´å‰"
            }
        }
    }

    // MARK: - è°ƒå‚UIäº‹ä»¶å¤„ç†

    /// çœŸå®æ‰‹åŠ¿é€‰æ‹©æ”¹å˜
    @objc private func groundTruthChanged(_ sender: UISegmentedControl) {
        switch sender.selectedSegmentIndex {
        case 0:
            currentGroundTruthGesture = .unknown
        case 1:
            currentGroundTruthGesture = .vSign
        case 2:
            currentGroundTruthGesture = .okSign
        case 3:
            currentGroundTruthGesture = .palm
        case 4:
            currentGroundTruthGesture = .fist
        case 5:
            currentGroundTruthGesture = .indexFinger
        default:
            currentGroundTruthGesture = .unknown
        }
        refreshStatsText()
    }

    /// é‡‡é›†æŒ‰é’®ç‚¹å‡»
    @objc private func collectButtonTapped() {
        isCollectingSamples.toggle()
        if isCollectingSamples {
            collectButton.setTitle("åœæ­¢é‡‡é›†", for: .normal)
            collectButton.backgroundColor = .systemRed
            statsUpdateCounter = 0
        } else {
            collectButton.setTitle("å¼€å§‹é‡‡é›†", for: .normal)
            collectButton.backgroundColor = .systemGreen
            refreshStatsText()
        }
    }

    /// é‡ç½®æŒ‰é’®ç‚¹å‡»
    @objc private func resetButtonTapped() {
        statsManager.reset()
        statsUpdateCounter = 0
        refreshStatsText()
    }

    /// å¯¼å‡ºæŒ‰é’®ç‚¹å‡»
    @objc private func exportButtonTapped() {
        let summary = statsManager.debugSummaryText()
        print("\n" + summary + "\n")
        refreshStatsText()
    }

    /// åˆ·æ–°ç»Ÿè®¡æ–‡æœ¬æ˜¾ç¤º
    private func refreshStatsText() {
        guard currentGroundTruthGesture != .unknown else {
            statsTextView.text = "è¯·å…ˆé€‰æ‹©çœŸå®æ‰‹åŠ¿ç±»å‹"
            return
        }

        let count = statsManager.sampleCount(for: currentGroundTruthGesture)
        guard count > 0 else {
            statsTextView.text = "å½“å‰æ‰‹åŠ¿ï¼š\(currentGroundTruthGesture.rawValue)\næ ·æœ¬å¸§æ•°ï¼š0\n\nç­‰å¾…é‡‡é›†æ•°æ®..."
            return
        }

        var lines: [String] = []
        lines.append("å½“å‰æ‰‹åŠ¿ï¼š\(currentGroundTruthGesture.rawValue)")
        lines.append("æ ·æœ¬å¸§æ•°ï¼š\(count)")
        lines.append("")

        // æ˜¾ç¤ºå…³é”®ç‰¹å¾çš„ç»Ÿè®¡ï¼ˆ3-5ä¸ªæœ€é‡è¦çš„ï¼‰
        let keyFeatures: [(String, KeyPath<HandGestureClassifier.HandGestureFeatureVector, CGFloat>)] = [
            ("thumbIndexGap", \HandGestureClassifier.HandGestureFeatureVector.thumbIndexGap),
            ("indexMiddleGap", \HandGestureClassifier.HandGestureFeatureVector.indexMiddleGap),
            ("lenIndex", \HandGestureClassifier.HandGestureFeatureVector.lenIndex),
            ("lenMiddle", \HandGestureClassifier.HandGestureFeatureVector.lenMiddle),
            ("thumbIndexGapNorm", \HandGestureClassifier.HandGestureFeatureVector.thumbIndexGapNorm)
        ]

        for (name, keyPath) in keyFeatures {
            if let stats = statsManager.stats(for: currentGroundTruthGesture, feature: keyPath) {
                lines.append("\(name):")
                lines.append("  mean=\(String(format: "%.3f", stats.mean))")
                lines.append("  min=\(String(format: "%.3f", stats.min))")
                lines.append("  max=\(String(format: "%.3f", stats.max))")
                lines.append("")
            }
        }

        statsTextView.text = lines.joined(separator: "\n")
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate

extension CameraViewController: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(
        _ output: AVCaptureOutput,
        didOutput sampleBuffer: CMSampleBuffer,
        from connection: AVCaptureConnection
    ) {
        processSampleBuffer(sampleBuffer)
    }
}
